

============================== 2022-01-05 04:50:32.857314 | eb767506-6a3d-4300-8bac-888eed83b193 ==============================
04:50:32.857314 [info ] [MainThread]: Running with dbt=1.0.1
04:50:32.857665 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, project_name='salesloft_demo', skip_profile_setup=False, defer=None, state=None, cls=<class 'dbt.task.init.InitTask'>, which='init', rpc_method=None)
04:50:32.857826 [debug] [MainThread]: Tracking: tracking
04:50:32.882651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a5c040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a4c1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a2c640>]}
04:50:32.884672 [info ] [MainThread]: Creating dbt configuration folder at /Users/bowt/.dbt
04:50:32.886738 [debug] [MainThread]: Starter project path: /usr/local/Cellar/dbt-bigquery/1.0.0/libexec/lib/python3.9/site-packages/dbt/include/starter_project
04:50:53.202020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1ab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1a670>]}


============================== 2022-01-05 14:58:39.507256 | 21a5e84a-1c08-40af-9b40-e8bb7e15d1d2 ==============================
14:58:39.507256 [info ] [MainThread]: Running with dbt=1.0.1
14:58:39.508032 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
14:58:39.508270 [debug] [MainThread]: Tracking: tracking
14:58:39.535925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085904f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085903d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108570fa0>]}
14:58:40.445444 [debug] [MainThread]: Executing "git --help"
14:58:40.482336 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
14:58:40.483287 [debug] [MainThread]: STDERR: "b''"
14:58:40.492577 [debug] [MainThread]: Acquiring new bigquery connection "debug"
14:58:40.493895 [debug] [MainThread]: Opening a new connection, currently in state init
14:58:40.498145 [debug] [MainThread]: On debug: select 1 as id
14:58:41.914423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a60130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a60ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a60fa0>]}
14:58:42.429290 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-01-05 14:58:50.647402 | 6ed6caba-b6d6-4a20-a174-017fe7d3c5a9 ==============================
14:58:50.647402 [info ] [MainThread]: Running with dbt=1.0.1
14:58:50.648188 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:58:50.648415 [debug] [MainThread]: Tracking: tracking
14:58:50.663369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fe3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fe39d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fe3850>]}
14:58:50.689552 [info ] [MainThread]: Unable to do partial parsing because profile has changed
14:58:50.689981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6ed6caba-b6d6-4a20-a174-017fe7d3c5a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10802db50>]}
14:58:50.726305 [debug] [MainThread]: Parsing macros/etc.sql
14:58:50.729523 [debug] [MainThread]: Parsing macros/catalog.sql
14:58:50.737015 [debug] [MainThread]: Parsing macros/adapters.sql
14:58:50.759539 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:58:50.761989 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:58:50.764435 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:58:50.768134 [debug] [MainThread]: Parsing macros/materializations/copy.sql
14:58:50.770662 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:58:50.785038 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:58:50.786674 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:58:50.790234 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:58:50.792383 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:58:50.793907 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:58:50.810052 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:58:50.820987 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:58:50.832361 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:58:50.836655 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:58:50.838312 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:58:50.839978 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:58:50.844072 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:58:50.854596 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:58:50.856024 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:58:50.865604 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:58:50.880683 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:58:50.887637 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:58:50.890304 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:58:50.897007 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:58:50.898221 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:58:50.900696 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:58:50.902953 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:58:50.908672 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:58:50.924075 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:58:50.925471 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:58:50.928034 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:58:50.929505 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:58:50.930330 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:58:50.930851 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:58:50.931501 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:58:50.932777 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:58:50.936891 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:58:50.944790 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:58:50.946853 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:58:50.949363 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:58:50.958349 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:58:50.961047 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:58:50.965169 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:58:50.971990 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:58:50.981431 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:58:51.167863 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
14:58:51.178329 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
14:58:51.224026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ed6caba-b6d6-4a20-a174-017fe7d3c5a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810a100>]}
14:58:51.230915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ed6caba-b6d6-4a20-a174-017fe7d3c5a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080c3c40>]}
14:58:51.231234 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:58:51.232467 [info ] [MainThread]: 
14:58:51.232901 [debug] [MainThread]: Acquiring new bigquery connection "master"
14:58:51.233710 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
14:58:51.233975 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:58:51.871632 [debug] [ThreadPool]: Acquiring new bigquery connection "create_salesloft-337304_salesloft-337304"
14:58:51.885250 [debug] [ThreadPool]: Acquiring new bigquery connection "create_salesloft-337304_salesloft-337304"
14:58:51.885587 [debug] [ThreadPool]: BigQuery adapter: Creating schema "salesloft-337304.salesloft-337304".
14:58:51.885826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:58:52.553017 [debug] [ThreadPool]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('POST https://bigquery.googleapis.com/bigquery/v2/projects/salesloft-337304/datasets?prettyPrint=false: Invalid dataset ID "salesloft-337304". Dataset IDs must be alphanumeric (plus underscores) and must be at most 1024 characters long.')
14:58:52.954039 [debug] [MainThread]: Connection 'master' was properly closed.
14:58:52.954420 [debug] [MainThread]: Connection 'create_salesloft-337304_salesloft-337304' was properly closed.
14:58:52.954799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081174f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080dae80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108071a30>]}


============================== 2022-01-05 15:09:41.022375 | d79d3a78-9393-499f-a7dd-d25ad24b2816 ==============================
15:09:41.022375 [info ] [MainThread]: Running with dbt=1.0.1
15:09:41.023755 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
15:09:41.024013 [debug] [MainThread]: Tracking: tracking
15:09:41.048897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfe04c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfe03a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfc0190>]}
15:09:41.914156 [debug] [MainThread]: Executing "git --help"
15:09:41.937198 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
15:09:41.938029 [debug] [MainThread]: STDERR: "b''"
15:09:41.945471 [debug] [MainThread]: Acquiring new bigquery connection "debug"
15:09:41.946382 [debug] [MainThread]: Opening a new connection, currently in state init
15:09:41.950967 [debug] [MainThread]: On debug: select 1 as id
15:09:43.506552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d49b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d49b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d49b400>]}
15:09:44.046001 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-01-05 15:09:50.137449 | c4a169b8-08db-4f66-b051-34a6eea6dca9 ==============================
15:09:50.137449 [info ] [MainThread]: Running with dbt=1.0.1
15:09:50.139472 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:09:50.140005 [debug] [MainThread]: Tracking: tracking
15:09:50.159707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1a9b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1a98b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1a99a0>]}
15:09:50.188206 [info ] [MainThread]: Unable to do partial parsing because profile has changed
15:09:50.189200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c4a169b8-08db-4f66-b051-34a6eea6dca9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1859a0>]}
15:09:50.224095 [debug] [MainThread]: Parsing macros/etc.sql
15:09:50.226811 [debug] [MainThread]: Parsing macros/catalog.sql
15:09:50.233755 [debug] [MainThread]: Parsing macros/adapters.sql
15:09:50.256972 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:09:50.259489 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:09:50.261888 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:09:50.265474 [debug] [MainThread]: Parsing macros/materializations/copy.sql
15:09:50.267873 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:09:50.281648 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:09:50.283153 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:09:50.286661 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:09:50.288765 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:09:50.290244 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:09:50.305763 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:09:50.317097 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:09:50.328057 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:09:50.332286 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:09:50.333938 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:09:50.335575 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:09:50.339656 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:09:50.350135 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:09:50.351519 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:09:50.360734 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:09:50.375711 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:09:50.382498 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:09:50.385161 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:09:50.391672 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:09:50.392861 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:09:50.395299 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:09:50.397425 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:09:50.403036 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:09:50.418445 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:09:50.419819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:09:50.422060 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:09:50.423508 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:09:50.424319 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:09:50.424836 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:09:50.425488 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:09:50.426795 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:09:50.430840 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:09:50.438606 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:09:50.440646 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:09:50.443101 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:09:50.452039 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:09:50.454729 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:09:50.458912 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:09:50.465777 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:09:50.474622 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:09:50.661770 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:09:50.672089 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:09:50.720141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4a169b8-08db-4f66-b051-34a6eea6dca9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2bd940>]}
15:09:50.726228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4a169b8-08db-4f66-b051-34a6eea6dca9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2bd580>]}
15:09:50.726832 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:09:50.728010 [info ] [MainThread]: 
15:09:50.728419 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:09:50.729145 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:09:50.729394 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:09:51.428919 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:09:51.429401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:09:52.136225 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:09:52.136798 [info ] [MainThread]: 
15:09:52.157852 [debug] [Thread-1  ]: Began running node model.salesloft_demo.my_first_dbt_model
15:09:52.158233 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.my_first_dbt_model...................... [RUN]
15:09:52.158924 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.my_first_dbt_model"
15:09:52.159150 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.my_first_dbt_model
15:09:52.159356 [debug] [Thread-1  ]: Compiling model.salesloft_demo.my_first_dbt_model
15:09:52.163520 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.my_first_dbt_model"
15:09:52.164389 [debug] [Thread-1  ]: finished collecting timing info
15:09:52.164599 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.my_first_dbt_model
15:09:52.208953 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.my_first_dbt_model"
15:09:52.209793 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:09:52.211073 [debug] [Thread-1  ]: On model.salesloft_demo.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.my_first_dbt_model"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:09:55.036952 [debug] [Thread-1  ]: finished collecting timing info
15:09:55.037499 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4a169b8-08db-4f66-b051-34a6eea6dca9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2394c0>]}
15:09:55.037875 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.my_first_dbt_model................. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.88s]
15:09:55.038231 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.my_first_dbt_model
15:09:55.038801 [debug] [Thread-3  ]: Began running node model.salesloft_demo.my_second_dbt_model
15:09:55.039171 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.my_second_dbt_model...................... [RUN]
15:09:55.039675 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.my_second_dbt_model"
15:09:55.039884 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.my_second_dbt_model
15:09:55.040065 [debug] [Thread-3  ]: Compiling model.salesloft_demo.my_second_dbt_model
15:09:55.042600 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.my_second_dbt_model"
15:09:55.043125 [debug] [Thread-3  ]: finished collecting timing info
15:09:55.043324 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.my_second_dbt_model
15:09:55.064781 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.my_second_dbt_model"
15:09:55.065473 [debug] [Thread-3  ]: Opening a new connection, currently in state init
15:09:55.066849 [debug] [Thread-3  ]: On model.salesloft_demo.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.my_second_dbt_model"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`my_first_dbt_model`
where id = 1;


15:09:56.498210 [debug] [Thread-3  ]: finished collecting timing info
15:09:56.498798 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4a169b8-08db-4f66-b051-34a6eea6dca9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e47b0d0>]}
15:09:56.499223 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.my_second_dbt_model................. [[32mOK[0m in 1.46s]
15:09:56.499624 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.my_second_dbt_model
15:09:56.501001 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:09:56.501409 [info ] [MainThread]: 
15:09:56.501716 [info ] [MainThread]: Finished running 1 table model, 1 view model in 5.77s.
15:09:56.501999 [debug] [MainThread]: Connection 'master' was properly closed.
15:09:56.502166 [debug] [MainThread]: Connection 'model.salesloft_demo.my_first_dbt_model' was properly closed.
15:09:56.502356 [debug] [MainThread]: Connection 'model.salesloft_demo.my_second_dbt_model' was properly closed.
15:09:56.507907 [info ] [MainThread]: 
15:09:56.508269 [info ] [MainThread]: [32mCompleted successfully[0m
15:09:56.508598 [info ] [MainThread]: 
15:09:56.508875 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
15:09:56.509240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e28ef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2adbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e466970>]}


============================== 2022-01-05 15:28:37.597337 | a4d52325-733f-41f9-ae7b-82198c8d8a07 ==============================
15:28:37.597337 [info ] [MainThread]: Running with dbt=1.0.1
15:28:37.598545 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:28:37.598880 [debug] [MainThread]: Tracking: tracking
15:28:37.619037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bfc370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bfcd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bfc130>]}
15:28:37.686861 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
15:28:37.687226 [debug] [MainThread]: Partial parsing: added file: salesloft_demo://models/example/questions.sql
15:28:37.687672 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
15:28:37.698909 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:28:37.709471 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:28:37.711546 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:28:37.749614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4d52325-733f-41f9-ae7b-82198c8d8a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113dc2fd0>]}
15:28:37.755770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4d52325-733f-41f9-ae7b-82198c8d8a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113be4340>]}
15:28:37.756084 [info ] [MainThread]: Found 3 models, 2 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:28:37.757511 [info ] [MainThread]: 
15:28:37.757943 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:28:37.758708 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:28:37.758952 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:28:38.548939 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:28:38.549887 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:28:39.158476 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:28:39.158979 [info ] [MainThread]: 
15:28:39.165789 [debug] [Thread-1  ]: Began running node model.salesloft_demo.my_first_dbt_model
15:28:39.166225 [info ] [Thread-1  ]: 1 of 3 START table model stack_overflow.my_first_dbt_model...................... [RUN]
15:28:39.166520 [debug] [Thread-2  ]: Began running node model.salesloft_demo.questions
15:28:39.167245 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.my_first_dbt_model"
15:28:39.167601 [info ] [Thread-2  ]: 2 of 3 START table model stack_overflow.questions............................... [RUN]
15:28:39.167879 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.my_first_dbt_model
15:28:39.168449 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:28:39.168729 [debug] [Thread-1  ]: Compiling model.salesloft_demo.my_first_dbt_model
15:28:39.168928 [debug] [Thread-2  ]: Began compiling node model.salesloft_demo.questions
15:28:39.171637 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.my_first_dbt_model"
15:28:39.171869 [debug] [Thread-2  ]: Compiling model.salesloft_demo.questions
15:28:39.175280 [debug] [Thread-2  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:28:39.175820 [debug] [Thread-1  ]: finished collecting timing info
15:28:39.176043 [debug] [Thread-2  ]: finished collecting timing info
15:28:39.176212 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.my_first_dbt_model
15:28:39.176424 [debug] [Thread-2  ]: Began executing node model.salesloft_demo.questions
15:28:39.199744 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:39.230264 [debug] [Thread-2  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:28:39.264242 [debug] [Thread-2  ]: Opening a new connection, currently in state init
15:28:39.266058 [debug] [Thread-2  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with UnawnseredQuestions as (

SELECT
    PQ.id
   ,PQ.title
   ,PQ.body
   ,PQ.creation_date
   ,PQ.tags
   ,PQ.owner_user_id
   ,PQ.view_count
   ,PQ.score
   ,U.display_name
   ,U.age
   ,U.reputation
   ,U.location
   ,RANK() OVER(ORDER BY PQ.view_count DESC)  AS popular_rank
   ,RANK() OVER(ORDER BY PQ.score DESC)       AS trending_rank


FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS PQ
    LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS U      ON U.id = PQ.owner_user_id

WHERE PQ.answer_count = 0

LIMIT 1
)

select *
from UnawnseredQuestions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:28:39.911154 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.my_first_dbt_model"
15:28:39.911975 [debug] [Thread-1  ]: On model.salesloft_demo.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.my_first_dbt_model"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:28:42.432013 [debug] [Thread-1  ]: finished collecting timing info
15:28:42.432534 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4d52325-733f-41f9-ae7b-82198c8d8a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d2fe50>]}
15:28:42.432911 [info ] [Thread-1  ]: 1 of 3 OK created table model stack_overflow.my_first_dbt_model................. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.27s]
15:28:42.433263 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.my_first_dbt_model
15:28:42.433650 [debug] [Thread-4  ]: Began running node model.salesloft_demo.my_second_dbt_model
15:28:42.433929 [info ] [Thread-4  ]: 3 of 3 START view model stack_overflow.my_second_dbt_model...................... [RUN]
15:28:42.434403 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.salesloft_demo.my_second_dbt_model"
15:28:42.434584 [debug] [Thread-4  ]: Began compiling node model.salesloft_demo.my_second_dbt_model
15:28:42.434760 [debug] [Thread-4  ]: Compiling model.salesloft_demo.my_second_dbt_model
15:28:42.437151 [debug] [Thread-4  ]: Writing injected SQL for node "model.salesloft_demo.my_second_dbt_model"
15:28:42.437670 [debug] [Thread-4  ]: finished collecting timing info
15:28:42.437871 [debug] [Thread-4  ]: Began executing node model.salesloft_demo.my_second_dbt_model
15:28:42.467923 [debug] [Thread-4  ]: Writing runtime SQL for node "model.salesloft_demo.my_second_dbt_model"
15:28:42.468620 [debug] [Thread-4  ]: Opening a new connection, currently in state init
15:28:42.470229 [debug] [Thread-4  ]: On model.salesloft_demo.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.my_second_dbt_model"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`my_first_dbt_model`
where id = 1;


15:28:43.573161 [debug] [Thread-4  ]: finished collecting timing info
15:28:43.573761 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4d52325-733f-41f9-ae7b-82198c8d8a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f21d90>]}
15:28:43.574210 [info ] [Thread-4  ]: 3 of 3 OK created view model stack_overflow.my_second_dbt_model................. [[32mOK[0m in 1.14s]
15:28:43.574618 [debug] [Thread-4  ]: Finished running node model.salesloft_demo.my_second_dbt_model
15:29:12.350659 [debug] [Thread-2  ]: finished collecting timing info
15:29:12.351267 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4d52325-733f-41f9-ae7b-82198c8d8a07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed74c0>]}
15:29:12.351702 [info ] [Thread-2  ]: 2 of 3 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (1.0 rows, 34.3 GB processed)[0m in 33.18s]
15:29:12.352113 [debug] [Thread-2  ]: Finished running node model.salesloft_demo.questions
15:29:12.353438 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:29:12.353845 [info ] [MainThread]: 
15:29:12.354152 [info ] [MainThread]: Finished running 2 table models, 1 view model in 34.60s.
15:29:12.354438 [debug] [MainThread]: Connection 'master' was properly closed.
15:29:12.354619 [debug] [MainThread]: Connection 'model.salesloft_demo.my_first_dbt_model' was properly closed.
15:29:12.354779 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:29:12.354936 [debug] [MainThread]: Connection 'model.salesloft_demo.my_second_dbt_model' was properly closed.
15:29:12.365339 [info ] [MainThread]: 
15:29:12.365696 [info ] [MainThread]: [32mCompleted successfully[0m
15:29:12.366023 [info ] [MainThread]: 
15:29:12.366294 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
15:29:12.366648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d43a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d43c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d3bd60>]}


============================== 2022-01-05 15:40:15.398178 | 7fccc438-5122-4bd7-b756-d391fb850cef ==============================
15:40:15.398178 [info ] [MainThread]: Running with dbt=1.0.1
15:40:15.399192 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:40:15.399472 [debug] [MainThread]: Tracking: tracking
15:40:15.417327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a1700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a18b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099a1400>]}
15:40:15.483193 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
15:40:15.483769 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.posts_questions
15:40:15.483918 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.users
15:40:15.484059 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
15:40:15.484327 [debug] [MainThread]: Partial parsing: deleted file: salesloft_demo://models/example/my_first_dbt_model.sql
15:40:15.495134 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:40:15.505615 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:40:15.540198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ad0c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b31d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b31df0>]}


============================== 2022-01-05 15:41:42.961279 | 31b2dc2f-468f-4bf0-85c8-a90b52853412 ==============================
15:41:42.961279 [info ] [MainThread]: Running with dbt=1.0.1
15:41:42.962198 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:41:42.962433 [debug] [MainThread]: Tracking: tracking
15:41:42.977798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa39a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa3220>]}
15:41:43.036896 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 1 files added, 1 files changed.
15:41:43.037243 [debug] [MainThread]: Partial parsing: added file: salesloft_demo://models/example/questions_view.sql
15:41:43.037727 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.posts_questions
15:41:43.037869 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.users
15:41:43.038009 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
15:41:43.038148 [debug] [MainThread]: Partial parsing: deleted file: salesloft_demo://models/example/my_first_dbt_model.sql
15:41:43.038292 [debug] [MainThread]: Partial parsing: deleted file: salesloft_demo://models/example/my_second_dbt_model.sql
15:41:43.048987 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_view.sql
15:41:43.059886 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:41:43.100359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '31b2dc2f-468f-4bf0-85c8-a90b52853412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec8c0d0>]}
15:41:43.106351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '31b2dc2f-468f-4bf0-85c8-a90b52853412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa32b0>]}
15:41:43.106824 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:41:43.108062 [info ] [MainThread]: 
15:41:43.108478 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:41:43.109181 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:41:43.109417 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:41:43.933580 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:41:43.933997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:41:44.610829 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:41:44.611461 [info ] [MainThread]: 
15:41:44.617434 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:41:44.617799 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:41:44.618351 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:41:44.618564 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:41:44.618777 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:41:44.622332 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:41:44.623972 [debug] [Thread-1  ]: finished collecting timing info
15:41:44.624191 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:41:44.642581 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:41:45.282948 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:41:45.283614 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with UnawnseredQuestions as (

SELECT
    PQ.id
   ,PQ.title
   ,PQ.body
   ,PQ.creation_date
   ,PQ.tags
   ,PQ.owner_user_id
   ,PQ.view_count
   ,PQ.score
   ,U.display_name
   ,U.age
   ,U.reputation
   ,U.location
   ,RANK() OVER(ORDER BY PQ.view_count DESC)  AS popular_rank
   ,RANK() OVER(ORDER BY PQ.score DESC)       AS trending_rank


FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS PQ
    LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS U      ON U.id = PQ.owner_user_id

WHERE PQ.answer_count = 0

LIMIT 1
)

select *
from UnawnseredQuestions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:42:14.168509 [debug] [Thread-1  ]: finished collecting timing info
15:42:14.169117 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31b2dc2f-468f-4bf0-85c8-a90b52853412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed69970>]}
15:42:14.169521 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (1.0 rows, 34.3 GB processed)[0m in 29.55s]
15:42:14.169892 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:42:14.170626 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:42:14.171105 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_view........................... [RUN]
15:42:14.171682 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_view"
15:42:14.171910 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_view
15:42:14.172098 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_view
15:42:14.174626 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_view"
15:42:14.175180 [debug] [Thread-3  ]: finished collecting timing info
15:42:14.175378 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_view
15:42:14.198371 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_view"
15:42:14.199053 [debug] [Thread-3  ]: Opening a new connection, currently in state init
15:42:14.200454 [debug] [Thread-3  ]: On model.salesloft_demo.questions_view: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_view"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_view`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`questions`
where id = 1;


15:42:15.675709 [debug] [Thread-3  ]: finished collecting timing info
15:42:15.676302 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31b2dc2f-468f-4bf0-85c8-a90b52853412', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ede2f70>]}
15:42:15.676721 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_view...................... [[32mOK[0m in 1.50s]
15:42:15.677114 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:42:15.678426 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:42:15.678858 [info ] [MainThread]: 
15:42:15.679155 [info ] [MainThread]: Finished running 1 table model, 1 view model in 32.57s.
15:42:15.679431 [debug] [MainThread]: Connection 'master' was properly closed.
15:42:15.679591 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:42:15.679742 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_view' was properly closed.
15:42:15.687493 [info ] [MainThread]: 
15:42:15.687875 [info ] [MainThread]: [32mCompleted successfully[0m
15:42:15.688201 [info ] [MainThread]: 
15:42:15.688468 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
15:42:15.688825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec27700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5cb6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebc43a0>]}


============================== 2022-01-05 15:45:09.815679 | 8de01dae-350a-40be-80cf-1f9383b9cff2 ==============================
15:45:09.815679 [info ] [MainThread]: Running with dbt=1.0.1
15:45:09.816366 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:45:09.816607 [debug] [MainThread]: Tracking: tracking
15:45:09.828561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111222370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111222d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111222130>]}
15:45:09.878980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:45:09.879471 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
15:45:09.892532 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:45:09.927389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8de01dae-350a-40be-80cf-1f9383b9cff2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113c50d0>]}
15:45:09.933548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8de01dae-350a-40be-80cf-1f9383b9cff2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11120a2b0>]}
15:45:09.934016 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:45:09.935385 [info ] [MainThread]: 
15:45:09.935798 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:45:09.936528 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:45:09.936765 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:45:10.592545 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:45:10.593052 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:45:11.216283 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:45:11.216854 [info ] [MainThread]: 
15:45:11.223761 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:45:11.224151 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:45:11.227833 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:45:11.228063 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:45:11.228272 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:45:11.232764 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:45:11.233359 [debug] [Thread-1  ]: finished collecting timing info
15:45:11.233574 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:45:11.250419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:45:11.889097 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:45:11.889806 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with questions as (
SELECT
    A.id
   ,A.title
   ,A.body
   ,A.creation_date
   ,A.tags
   ,A.owner_user_id
   ,A.view_count
   ,A.score
   ,B.display_name
   ,B.age
   ,B.reputation
   ,B.location
   ,RANK() OVER(ORDER BY A.view_count DESC) AS popular_rank
   ,RANK() OVER(ORDER BY A.score DESC) AS trending_rank
FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS A
LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS B
  ON A.id = B.owner_user_id
WHERE A.answer_count = 0
)
SELECT *
FROM questions
  );
  
15:45:12.572788 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Name owner_user_id not found inside B at [34:15]')
15:45:14.331919 [debug] [Thread-1  ]: finished collecting timing info
15:45:14.332520 [debug] [Thread-1  ]: Database Error in model questions (models/example/questions.sql)
  Name owner_user_id not found inside B at [34:15]
  compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:45:14.332923 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8de01dae-350a-40be-80cf-1f9383b9cff2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114d1430>]}
15:45:14.333367 [error] [Thread-1  ]: 1 of 2 ERROR creating table model stack_overflow.questions...................... [[31mERROR[0m in 3.11s]
15:45:14.333803 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:45:14.334610 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:45:14.335013 [info ] [Thread-3  ]: 2 of 2 SKIP relation stack_overflow.questions_view.............................. [[33mSKIP[0m]
15:45:14.335687 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:45:14.337040 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:45:14.337501 [info ] [MainThread]: 
15:45:14.337832 [info ] [MainThread]: Finished running 1 table model, 1 view model in 4.40s.
15:45:14.338115 [debug] [MainThread]: Connection 'master' was properly closed.
15:45:14.338281 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:45:14.345396 [info ] [MainThread]: 
15:45:14.345776 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:45:14.346437 [info ] [MainThread]: 
15:45:14.346709 [error] [MainThread]: [33mDatabase Error in model questions (models/example/questions.sql)[0m
15:45:14.346973 [error] [MainThread]:   Name owner_user_id not found inside B at [34:15]
15:45:14.347225 [error] [MainThread]:   compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:45:14.347476 [info ] [MainThread]: 
15:45:14.347729 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
15:45:14.348078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132eb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113bd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112cf460>]}


============================== 2022-01-05 15:46:58.599606 | 5361afde-75ea-41ed-80e6-484deec34cbc ==============================
15:46:58.599606 [info ] [MainThread]: Running with dbt=1.0.1
15:46:58.600314 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:46:58.600521 [debug] [MainThread]: Tracking: tracking
15:46:58.613479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f723310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f723cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f723c40>]}
15:46:58.663082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:46:58.663795 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.posts_questions
15:46:58.663971 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.users
15:46:58.664141 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
15:46:58.676871 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_view.sql
15:46:58.687604 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:46:58.731922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5361afde-75ea-41ed-80e6-484deec34cbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8dca30>]}
15:46:58.736812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5361afde-75ea-41ed-80e6-484deec34cbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f725a60>]}
15:46:58.737083 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:46:58.738288 [info ] [MainThread]: 
15:46:58.738678 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:46:58.739418 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:46:58.739624 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:46:59.356644 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:46:59.357158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:46:59.984094 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:46:59.984711 [info ] [MainThread]: 
15:46:59.988784 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:46:59.989146 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:46:59.989647 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:46:59.989831 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:46:59.990026 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:46:59.993652 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:46:59.994291 [debug] [Thread-1  ]: finished collecting timing info
15:46:59.994505 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:47:00.011374 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:47:00.666698 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:47:00.667385 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with questions as (
SELECT
    A.id
   ,A.title
   ,A.body
   ,A.creation_date
   ,A.tags
   ,A.owner_user_id
   ,A.view_count
   ,A.score
   ,B.display_name
   ,B.age
   ,B.reputation
   ,B.location
   ,RANK() OVER(ORDER BY A.view_count DESC) AS popular_rank
   ,RANK() OVER(ORDER BY A.score DESC) AS trending_rank
FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS A
LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS B
  ON A.id = B.owner_user_id
WHERE A.answer_count = 0
)
SELECT *
FROM questions
  );
  
15:47:01.394545 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Name owner_user_id not found inside B at [34:15]')
15:47:02.155565 [debug] [Thread-1  ]: finished collecting timing info
15:47:02.156110 [debug] [Thread-1  ]: Database Error in model questions (models/example/questions.sql)
  Name owner_user_id not found inside B at [34:15]
  compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:47:02.156492 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5361afde-75ea-41ed-80e6-484deec34cbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa07460>]}
15:47:02.156919 [error] [Thread-1  ]: 1 of 2 ERROR creating table model stack_overflow.questions...................... [[31mERROR[0m in 2.17s]
15:47:02.157348 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:47:02.158069 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:47:02.158341 [info ] [Thread-3  ]: 2 of 2 SKIP relation stack_overflow.questions_view.............................. [[33mSKIP[0m]
15:47:02.158794 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:47:02.159875 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:47:02.160266 [info ] [MainThread]: 
15:47:02.160572 [info ] [MainThread]: Finished running 1 table model, 1 view model in 3.42s.
15:47:02.160859 [debug] [MainThread]: Connection 'master' was properly closed.
15:47:02.161023 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:47:02.166875 [info ] [MainThread]: 
15:47:02.167334 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:47:02.167704 [info ] [MainThread]: 
15:47:02.167989 [error] [MainThread]: [33mDatabase Error in model questions (models/example/questions.sql)[0m
15:47:02.168256 [error] [MainThread]:   Name owner_user_id not found inside B at [34:15]
15:47:02.168508 [error] [MainThread]:   compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:47:02.168801 [info ] [MainThread]: 
15:47:02.169064 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
15:47:02.169512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6fdeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f794760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9b67c0>]}


============================== 2022-01-05 15:47:53.239347 | 665e0357-2488-4421-90ed-e2b2fc539aaf ==============================
15:47:53.239347 [info ] [MainThread]: Running with dbt=1.0.1
15:47:53.240200 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:47:53.240608 [debug] [MainThread]: Tracking: tracking
15:47:53.255356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c081040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0818b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0812e0>]}
15:47:53.313313 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:47:53.313903 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
15:47:53.328937 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:47:53.376514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '665e0357-2488-4421-90ed-e2b2fc539aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c267f40>]}
15:47:53.385412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '665e0357-2488-4421-90ed-e2b2fc539aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1a0460>]}
15:47:53.385894 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:47:53.387893 [info ] [MainThread]: 
15:47:53.388625 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:47:53.389874 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:47:53.390411 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:47:54.049300 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:47:54.049727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:47:54.735184 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:47:54.735821 [info ] [MainThread]: 
15:47:54.742477 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:47:54.742891 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:47:54.746738 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:47:54.747004 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:47:54.747214 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:47:54.750667 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:47:54.751247 [debug] [Thread-1  ]: finished collecting timing info
15:47:54.751458 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:47:54.768043 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:47:55.416351 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:47:55.416976 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with UnawnseredQuestions as (

SELECT
    PQ.id
   ,PQ.title
   ,PQ.body
   ,PQ.creation_date
   ,PQ.tags
   ,PQ.owner_user_id
   ,PQ.view_count
   ,PQ.score
   ,U.display_name
   ,U.age
   ,U.reputation
   ,U.location
   ,RANK() OVER(ORDER BY PQ.view_count DESC) AS popular_rank
   ,RANK() OVER(ORDER BY PQ.score DESC) AS trending_rank
FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS A
LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS U
ON U.id = PQ.owner_user_id

WHERE PQ.answer_count = 0

LIMIT 1
)

select *
from UnawnseredQuestions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:47:56.110556 [debug] [Thread-1  ]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: PQ at [35:11]')
15:47:57.738748 [debug] [Thread-1  ]: finished collecting timing info
15:47:57.739308 [debug] [Thread-1  ]: Database Error in model questions (models/example/questions.sql)
  Unrecognized name: PQ at [35:11]
  compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:47:57.739723 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '665e0357-2488-4421-90ed-e2b2fc539aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c352430>]}
15:47:57.740183 [error] [Thread-1  ]: 1 of 2 ERROR creating table model stack_overflow.questions...................... [[31mERROR[0m in 3.00s]
15:47:57.740624 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:47:57.741400 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:47:57.741797 [info ] [Thread-3  ]: 2 of 2 SKIP relation stack_overflow.questions_view.............................. [[33mSKIP[0m]
15:47:57.742205 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:47:57.743336 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:47:57.743748 [info ] [MainThread]: 
15:47:57.744050 [info ] [MainThread]: Finished running 1 table model, 1 view model in 4.36s.
15:47:57.744331 [debug] [MainThread]: Connection 'master' was properly closed.
15:47:57.744499 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:47:57.749905 [info ] [MainThread]: 
15:47:57.750289 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:47:57.750600 [info ] [MainThread]: 
15:47:57.750853 [error] [MainThread]: [33mDatabase Error in model questions (models/example/questions.sql)[0m
15:47:57.751242 [error] [MainThread]:   Unrecognized name: PQ at [35:11]
15:47:57.751489 [error] [MainThread]:   compiled SQL at target/run/salesloft_demo/models/example/questions.sql
15:47:57.751729 [info ] [MainThread]: 
15:47:57.751974 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
15:47:57.752316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2307f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c24bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c302a30>]}


============================== 2022-01-05 15:48:12.424290 | 8931c64c-de0c-4932-a356-0f5591bde271 ==============================
15:48:12.424290 [info ] [MainThread]: Running with dbt=1.0.1
15:48:12.425153 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:48:12.425386 [debug] [MainThread]: Tracking: tracking
15:48:12.439738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e540850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5402e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e540130>]}
15:48:12.491580 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:48:12.492127 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
15:48:12.505596 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:48:12.543368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8931c64c-de0c-4932-a356-0f5591bde271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e741fd0>]}
15:48:12.548624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8931c64c-de0c-4932-a356-0f5591bde271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e682280>]}
15:48:12.548911 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:48:12.550087 [info ] [MainThread]: 
15:48:12.550470 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:48:12.551242 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:48:12.551606 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:48:13.187232 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:48:13.187656 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:48:13.926289 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:48:13.926851 [info ] [MainThread]: 
15:48:13.932553 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:48:13.932946 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:48:13.936877 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:48:13.937128 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:48:13.937349 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:48:13.940838 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:48:13.941411 [debug] [Thread-1  ]: finished collecting timing info
15:48:13.941625 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:48:13.958528 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:48:14.670082 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:48:14.670793 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with UnawnseredQuestions as (

SELECT
    PQ.id
   ,PQ.title
   ,PQ.body
   ,PQ.creation_date
   ,PQ.tags
   ,PQ.owner_user_id
   ,PQ.view_count
   ,PQ.score
   ,U.display_name
   ,U.age
   ,U.reputation
   ,U.location
   ,RANK() OVER(ORDER BY PQ.view_count DESC) AS popular_rank
   ,RANK() OVER(ORDER BY PQ.score DESC) AS trending_rank
FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS PQ
LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS U
ON U.id = PQ.owner_user_id

WHERE PQ.answer_count = 0

LIMIT 1
)

select *
from UnawnseredQuestions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:48:40.866084 [debug] [Thread-1  ]: finished collecting timing info
15:48:40.868094 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8931c64c-de0c-4932-a356-0f5591bde271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6e1c10>]}
15:48:40.868669 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (1.0 rows, 34.3 GB processed)[0m in 26.93s]
15:48:40.869135 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:48:40.869834 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:48:40.870372 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_view........................... [RUN]
15:48:40.871109 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_view"
15:48:40.871356 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_view
15:48:40.871609 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_view
15:48:40.874542 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_view"
15:48:40.875205 [debug] [Thread-3  ]: finished collecting timing info
15:48:40.875417 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_view
15:48:40.897350 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_view"
15:48:40.898045 [debug] [Thread-3  ]: Opening a new connection, currently in state init
15:48:40.899510 [debug] [Thread-3  ]: On model.salesloft_demo.questions_view: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_view"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_view`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`questions`
where id = 1;


15:48:42.270212 [debug] [Thread-3  ]: finished collecting timing info
15:48:42.270814 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8931c64c-de0c-4932-a356-0f5591bde271', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e898ca0>]}
15:48:42.271258 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_view...................... [[32mOK[0m in 1.40s]
15:48:42.271670 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:48:42.273083 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:48:42.273556 [info ] [MainThread]: 
15:48:42.273884 [info ] [MainThread]: Finished running 1 table model, 1 view model in 29.72s.
15:48:42.274166 [debug] [MainThread]: Connection 'master' was properly closed.
15:48:42.274331 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:48:42.274490 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_view' was properly closed.
15:48:42.285344 [info ] [MainThread]: 
15:48:42.285721 [info ] [MainThread]: [32mCompleted successfully[0m
15:48:42.286052 [info ] [MainThread]: 
15:48:42.286321 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
15:48:42.286677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e712670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e72bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6eb040>]}


============================== 2022-01-05 15:48:57.489073 | 7b44c935-08e7-4f8f-b23a-3e94f85dc10a ==============================
15:48:57.489073 [info ] [MainThread]: Running with dbt=1.0.1
15:48:57.489810 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:48:57.490029 [debug] [MainThread]: Tracking: tracking
15:48:57.503843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703adf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703a9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703a220>]}
15:48:57.553147 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:48:57.553652 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
15:48:57.565307 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
15:48:57.600602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b44c935-08e7-4f8f-b23a-3e94f85dc10a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071f30d0>]}
15:48:57.605683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b44c935-08e7-4f8f-b23a-3e94f85dc10a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10715a370>]}
15:48:57.605970 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:48:57.607198 [info ] [MainThread]: 
15:48:57.607596 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:48:57.608316 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
15:48:57.608632 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:48:58.256118 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
15:48:58.256540 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:48:58.915324 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
15:48:58.915885 [info ] [MainThread]: 
15:48:58.921387 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
15:48:58.921756 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
15:48:58.925519 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
15:48:58.925760 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
15:48:58.925976 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
15:48:58.929425 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
15:48:58.929985 [debug] [Thread-1  ]: finished collecting timing info
15:48:58.930208 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
15:48:58.947067 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:48:59.592592 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
15:48:59.593345 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



with UnawnseredQuestions as (

SELECT
    PQ.id
   ,PQ.title
   ,PQ.body
   ,PQ.creation_date
   ,PQ.tags
   ,PQ.owner_user_id
   ,PQ.view_count
   ,PQ.score
   ,U.display_name
   ,U.age
   ,U.reputation
   ,U.location
   ,RANK() OVER(ORDER BY PQ.view_count DESC) AS popular_rank
   ,RANK() OVER(ORDER BY PQ.score DESC) AS trending_rank
FROM `bigquery-public-data`.`stackoverflow`.`posts_questions` AS PQ
LEFT JOIN `bigquery-public-data`.`stackoverflow`.`users`  AS U
ON U.id = PQ.owner_user_id

WHERE PQ.answer_count = 0
)

select *
from UnawnseredQuestions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
15:53:06.743916 [debug] [Thread-1  ]: finished collecting timing info
15:53:06.745662 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b44c935-08e7-4f8f-b23a-3e94f85dc10a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071ba820>]}
15:53:06.746180 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 247.82s]
15:53:06.746570 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
15:53:06.747282 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_view
15:53:06.747917 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_view........................... [RUN]
15:53:06.748618 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_view"
15:53:06.748827 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_view
15:53:06.749023 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_view
15:53:06.752567 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_view"
15:53:06.754186 [debug] [Thread-3  ]: finished collecting timing info
15:53:06.754466 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_view
15:53:06.780865 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_view"
15:53:06.781770 [debug] [Thread-3  ]: Opening a new connection, currently in state init
15:53:06.785448 [debug] [Thread-3  ]: On model.salesloft_demo.questions_view: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_view"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_view`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`questions`
where id = 1;


15:53:08.319552 [debug] [Thread-3  ]: finished collecting timing info
15:53:08.320200 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b44c935-08e7-4f8f-b23a-3e94f85dc10a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10731de20>]}
15:53:08.320846 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_view...................... [[32mOK[0m in 1.57s]
15:53:08.321357 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_view
15:53:08.322945 [debug] [MainThread]: Acquiring new bigquery connection "master"
15:53:08.323404 [info ] [MainThread]: 
15:53:08.323727 [info ] [MainThread]: Finished running 1 table model, 1 view model in 250.72s.
15:53:08.324021 [debug] [MainThread]: Connection 'master' was properly closed.
15:53:08.324195 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
15:53:08.324357 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_view' was properly closed.
15:53:08.332895 [info ] [MainThread]: 
15:53:08.333335 [info ] [MainThread]: [32mCompleted successfully[0m
15:53:08.333719 [info ] [MainThread]: 
15:53:08.334265 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
15:53:08.334853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071e9760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107203f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c43a0>]}


============================== 2022-01-05 16:00:15.322664 | cd94597a-4ecd-4e3f-845f-b7446b4ce446 ==============================
16:00:15.322664 [info ] [MainThread]: Running with dbt=1.0.1
16:00:15.324097 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:00:15.324393 [debug] [MainThread]: Tracking: tracking
16:00:15.344345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fad2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fad25e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fad2e20>]}
16:00:15.417916 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
16:00:15.418383 [debug] [MainThread]: Partial parsing: added file: salesloft_demo://models/example/questions_vw.sql
16:00:15.418598 [debug] [MainThread]: Partial parsing: deleted file: salesloft_demo://models/example/questions_view.sql
16:00:15.418975 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
16:00:15.433445 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:00:15.448099 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:00:15.485725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd94597a-4ecd-4e3f-845f-b7446b4ce446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fca20d0>]}
16:00:15.494063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd94597a-4ecd-4e3f-845f-b7446b4ce446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb1a6d0>]}
16:00:15.494460 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:00:15.495975 [info ] [MainThread]: 
16:00:15.496504 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:00:15.497484 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:00:15.497934 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:00:16.397334 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:00:16.397855 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:00:17.089052 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:00:17.089542 [info ] [MainThread]: 
16:00:17.096122 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:00:17.096548 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:00:17.100982 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:00:17.101282 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:00:17.101512 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:00:17.105624 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:00:17.107319 [debug] [Thread-1  ]: finished collecting timing info
16:00:17.107570 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:00:17.125349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:00:17.768434 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:00:17.769154 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



WITH questions AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.OWNER_USER_ID
    ,B.VIEW_COUNT
    ,B.SCORE
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS popular_rank
    ,RANK() OVER(ORDER BY B.SCORE DESC) AS trending_rank
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.id = B.owner_user_id
  WHERE
    B.answer_count = 0
    AND B.owner_user_id IS NOT NULL
)
SELECT *
FROM questions

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
16:03:46.510477 [debug] [Thread-1  ]: finished collecting timing info
16:03:46.511624 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd94597a-4ecd-4e3f-845f-b7446b4ce446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc3abb0>]}
16:03:46.512031 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 209.41s]
16:03:46.512392 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:03:46.512990 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:03:46.513534 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:03:46.514430 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:03:46.514701 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:03:46.514894 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:03:46.517784 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:03:46.518805 [debug] [Thread-3  ]: finished collecting timing info
16:03:46.519039 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:03:46.541665 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:03:46.542415 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:03:46.544447 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `salesloft-337304`.`stack_overflow`.`questions`
where id = 1;


16:03:48.020551 [debug] [Thread-3  ]: finished collecting timing info
16:03:48.021099 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd94597a-4ecd-4e3f-845f-b7446b4ce446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdf3e80>]}
16:03:48.021480 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.51s]
16:03:48.021827 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:03:48.023048 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:03:48.023461 [info ] [MainThread]: 
16:03:48.023772 [info ] [MainThread]: Finished running 1 table model, 1 view model in 212.53s.
16:03:48.024058 [debug] [MainThread]: Connection 'master' was properly closed.
16:03:48.024225 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:03:48.024383 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:03:48.030026 [info ] [MainThread]: 
16:03:48.030431 [info ] [MainThread]: [32mCompleted successfully[0m
16:03:48.030923 [info ] [MainThread]: 
16:03:48.031214 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:03:48.031588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb7f730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fabcd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbdec10>]}


============================== 2022-01-05 16:07:27.412637 | d9f2f35b-0a42-4b88-966e-825ad6c3466e ==============================
16:07:27.412637 [info ] [MainThread]: Running with dbt=1.0.1
16:07:27.413840 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:07:27.414171 [debug] [MainThread]: Tracking: tracking
16:07:27.435634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de201c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de20a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de20e20>]}
16:07:27.510639 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
16:07:27.511203 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions_vw.sql
16:07:27.511594 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
16:07:27.528656 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:07:27.544292 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:07:27.583965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9f2f35b-0a42-4b88-966e-825ad6c3466e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfe5f70>]}
16:07:27.591818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9f2f35b-0a42-4b88-966e-825ad6c3466e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de20c40>]}
16:07:27.592232 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:07:27.593977 [info ] [MainThread]: 
16:07:27.594570 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:07:27.595546 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:07:27.596002 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:07:28.437508 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:07:28.437916 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:07:29.160146 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:07:29.160578 [info ] [MainThread]: 
16:07:29.166808 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:07:29.167172 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:07:29.171224 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:07:29.171560 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:07:29.171792 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:07:29.175338 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:07:29.176328 [debug] [Thread-1  ]: finished collecting timing info
16:07:29.176568 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:07:29.196119 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:07:29.877312 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:07:29.879086 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    /*
    Configured on 10/28/2021 by Thomas Randazzo
    Used to analyze data for Unawnsered Questions in Stack OverFlow
*/



WITH QUESTIONS AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.OWNER_USER_ID
    ,B.VIEW_COUNT
    ,B.SCORE
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS VW_RNK
    ,RANK() OVER(ORDER BY B.SCORE DESC) AS SCORE_RNK
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.ID = B.OWNER_USER_ID
  WHERE
    B.ANSWER_COUNT = 0
    AND B.OWNER_USER_ID IS NOT NULL
)
SELECT *
FROM QUESTIONS

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
16:11:08.015457 [debug] [Thread-1  ]: finished collecting timing info
16:11:08.017180 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9f2f35b-0a42-4b88-966e-825ad6c3466e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df90be0>]}
16:11:08.017667 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 218.85s]
16:11:08.018045 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:11:08.018604 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:11:08.019019 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:11:08.019513 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:11:08.019696 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:11:08.019876 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:11:08.022717 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:11:08.023594 [debug] [Thread-3  ]: finished collecting timing info
16:11:08.024055 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:11:08.048756 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:11:08.049550 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:11:08.052011 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

SELECT *
FROM `salesloft-337304`.`stack_overflow`.`questions`;


16:11:09.366825 [debug] [Thread-3  ]: finished collecting timing info
16:11:09.367642 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9f2f35b-0a42-4b88-966e-825ad6c3466e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e13ffa0>]}
16:11:09.368052 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.35s]
16:11:09.368406 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:11:09.369665 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:11:09.370116 [info ] [MainThread]: 
16:11:09.370430 [info ] [MainThread]: Finished running 1 table model, 1 view model in 221.78s.
16:11:09.370715 [debug] [MainThread]: Connection 'master' was properly closed.
16:11:09.370878 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:11:09.371037 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:11:09.378086 [info ] [MainThread]: 
16:11:09.378556 [info ] [MainThread]: [32mCompleted successfully[0m
16:11:09.378992 [info ] [MainThread]: 
16:11:09.379277 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:11:09.379659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df3dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfcd0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e163160>]}


============================== 2022-01-05 16:16:37.594060 | eb5918ec-68fd-4c4f-87df-8e2a9ca94e23 ==============================
16:16:37.594060 [info ] [MainThread]: Running with dbt=1.0.1
16:16:37.596127 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:16:37.596773 [debug] [MainThread]: Tracking: tracking
16:16:37.618788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b993580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b993220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9931f0>]}
16:16:37.656281 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
16:16:37.656973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eb5918ec-68fd-4c4f-87df-8e2a9ca94e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9c8fa0>]}
16:16:37.702871 [debug] [MainThread]: Parsing macros/etc.sql
16:16:37.705835 [debug] [MainThread]: Parsing macros/catalog.sql
16:16:37.714804 [debug] [MainThread]: Parsing macros/adapters.sql
16:16:37.747718 [debug] [MainThread]: Parsing macros/materializations/seed.sql
16:16:37.751201 [debug] [MainThread]: Parsing macros/materializations/view.sql
16:16:37.754524 [debug] [MainThread]: Parsing macros/materializations/table.sql
16:16:37.760214 [debug] [MainThread]: Parsing macros/materializations/copy.sql
16:16:37.764774 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
16:16:37.785925 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
16:16:37.788114 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
16:16:37.794001 [debug] [MainThread]: Parsing macros/materializations/configs.sql
16:16:37.797920 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
16:16:37.800316 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
16:16:37.823435 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
16:16:37.839420 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
16:16:37.855412 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
16:16:37.863303 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
16:16:37.865843 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
16:16:37.868225 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
16:16:37.874380 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
16:16:37.890199 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
16:16:37.893026 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
16:16:37.908336 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
16:16:37.932157 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
16:16:37.941779 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
16:16:37.945906 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
16:16:37.956268 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
16:16:37.958185 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
16:16:37.962542 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
16:16:37.966143 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
16:16:37.974334 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
16:16:37.998227 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
16:16:38.000275 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
16:16:38.003389 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
16:16:38.005485 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
16:16:38.006702 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
16:16:38.007607 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
16:16:38.009034 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
16:16:38.010958 [debug] [MainThread]: Parsing macros/etc/statement.sql
16:16:38.017123 [debug] [MainThread]: Parsing macros/etc/datetime.sql
16:16:38.031019 [debug] [MainThread]: Parsing macros/adapters/schema.sql
16:16:38.034426 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
16:16:38.037833 [debug] [MainThread]: Parsing macros/adapters/relation.sql
16:16:38.051181 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
16:16:38.054974 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
16:16:38.061360 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
16:16:38.071788 [debug] [MainThread]: Parsing macros/adapters/columns.sql
16:16:38.086326 [debug] [MainThread]: Parsing tests/generic/builtin.sql
16:16:38.374169 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:16:38.389162 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:16:38.482179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb5918ec-68fd-4c4f-87df-8e2a9ca94e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb92fd0>]}
16:16:38.490075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb5918ec-68fd-4c4f-87df-8e2a9ca94e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba231f0>]}
16:16:38.490483 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:16:38.492785 [info ] [MainThread]: 
16:16:38.493804 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:16:38.495519 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:16:38.496072 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:16:39.871719 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:16:39.872023 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:16:40.559084 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:16:40.559864 [info ] [MainThread]: 
16:16:40.566129 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:16:40.566505 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:16:40.567041 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:16:40.567232 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:16:40.567436 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:16:40.570927 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:16:40.572161 [debug] [Thread-1  ]: finished collecting timing info
16:16:40.572374 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:16:40.589121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:16:41.250241 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:16:41.250977 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    

WITH QUESTIONS AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.VIEW_COUNT
    ,B.SCORE
    ,B.OWNER_USER_ID
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS POP_RNK
    ,RANK() OVER(ORDER BY B.SCORE DESC) AS TREND_RNK
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.ID = B.OWNER_USER_ID
  WHERE
    B.ANSWER_COUNT = 0
    AND B.OWNER_USER_ID IS NOT NULL
)
SELECT *
FROM QUESTIONS
  );
  
16:19:39.634601 [debug] [Thread-1  ]: finished collecting timing info
16:19:39.636479 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb5918ec-68fd-4c4f-87df-8e2a9ca94e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb1c5b0>]}
16:19:39.636979 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 179.07s]
16:19:39.637378 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:19:39.637968 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:19:39.638267 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:19:39.638875 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:19:39.639074 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:19:39.639261 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:19:39.641929 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:19:39.643018 [debug] [Thread-3  ]: finished collecting timing info
16:19:39.643271 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:19:39.665689 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:19:39.666352 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:19:39.668481 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

SELECT *
FROM `salesloft-337304`.`stack_overflow`.`questions`;


16:19:40.881268 [debug] [Thread-3  ]: finished collecting timing info
16:19:40.881872 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb5918ec-68fd-4c4f-87df-8e2a9ca94e23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd07e50>]}
16:19:40.882245 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.24s]
16:19:40.882619 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:19:40.883859 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:19:40.884282 [info ] [MainThread]: 
16:19:40.884606 [info ] [MainThread]: Finished running 1 table model, 1 view model in 182.39s.
16:19:40.884899 [debug] [MainThread]: Connection 'master' was properly closed.
16:19:40.885071 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:19:40.885236 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:19:40.911741 [info ] [MainThread]: 
16:19:40.912133 [info ] [MainThread]: [32mCompleted successfully[0m
16:19:40.912460 [info ] [MainThread]: 
16:19:40.912728 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:19:40.913087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba237c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba627f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd20790>]}


============================== 2022-01-05 16:32:49.014189 | 56988360-0c04-43c2-848d-2e049730b88f ==============================
16:32:49.014189 [info ] [MainThread]: Running with dbt=1.0.1
16:32:49.015495 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:32:49.015871 [debug] [MainThread]: Tracking: tracking
16:32:49.033415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f00f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f008e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f00250>]}
16:32:49.102173 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
16:32:49.102517 [debug] [MainThread]: Partial parsing: added file: salesloft_demo://tests/questions_test.sql
16:32:49.102977 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.posts_questions
16:32:49.103121 [debug] [MainThread]: Partial parsing: deleted source source.salesloft_demo.stackoverflow_questions.users
16:32:49.103264 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
16:32:49.103453 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions.sql
16:32:49.114209 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:32:49.185273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '56988360-0c04-43c2-848d-2e049730b88f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080ec0d0>]}
16:32:49.194304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '56988360-0c04-43c2-848d-2e049730b88f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f00eb0>]}
16:32:49.194680 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:32:49.196026 [info ] [MainThread]: 
16:32:49.196461 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:32:49.197348 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:32:49.197600 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:32:50.024359 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:32:50.024897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:32:50.641235 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:32:50.641811 [info ] [MainThread]: 
16:32:50.647597 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:32:50.647998 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:32:50.648534 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:32:50.648742 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:32:50.648972 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:32:50.652547 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:32:50.655143 [debug] [Thread-1  ]: finished collecting timing info
16:32:50.655457 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:32:50.674302 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:32:51.332634 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:32:51.334501 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    

WITH QUESTIONS AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.VIEW_COUNT
    ,B.SCORE
    ,B.OWNER_USER_ID
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,DENSE_RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS POP_RNK
    ,DENSE_RANK() OVER(ORDER BY B.SCORE DESC) AS TREND_RNK
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.ID = B.OWNER_USER_ID
  WHERE
    B.ANSWER_COUNT = 0
    AND B.OWNER_USER_ID IS NOT NULL
)
SELECT *
FROM QUESTIONS
  );
  
16:35:55.017450 [debug] [Thread-1  ]: finished collecting timing info
16:35:55.018783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56988360-0c04-43c2-848d-2e049730b88f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10800cd30>]}
16:35:55.019185 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 184.37s]
16:35:55.019543 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:35:55.020054 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:35:55.020546 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:35:55.021063 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:35:55.021261 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:35:55.021456 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:35:55.023876 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:35:55.024807 [debug] [Thread-3  ]: finished collecting timing info
16:35:55.025023 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:35:55.047339 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:35:55.048085 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:35:55.050410 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

SELECT *
FROM `salesloft-337304`.`stack_overflow`.`questions`;


16:35:56.261689 [debug] [Thread-3  ]: finished collecting timing info
16:35:56.262335 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56988360-0c04-43c2-848d-2e049730b88f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080bfe50>]}
16:35:56.262824 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.24s]
16:35:56.263249 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:35:56.264539 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:35:56.264987 [info ] [MainThread]: 
16:35:56.265304 [info ] [MainThread]: Finished running 1 table model, 1 view model in 187.07s.
16:35:56.265645 [debug] [MainThread]: Connection 'master' was properly closed.
16:35:56.265889 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:35:56.266068 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:35:56.272437 [info ] [MainThread]: 
16:35:56.272811 [info ] [MainThread]: [32mCompleted successfully[0m
16:35:56.273143 [info ] [MainThread]: 
16:35:56.273420 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:35:56.273780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ee93a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080b81f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f7dee0>]}


============================== 2022-01-05 16:36:24.251164 | 0aa29662-f08e-41e5-95b4-14666fbe317a ==============================
16:36:24.251164 [info ] [MainThread]: Running with dbt=1.0.1
16:36:24.252445 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:36:24.252782 [debug] [MainThread]: Tracking: tracking
16:36:24.274439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067fe7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f78b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f7850>]}
16:36:24.358934 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:36:24.359912 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
16:36:24.376141 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:36:24.392286 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:36:24.453258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0aa29662-f08e-41e5-95b4-14666fbe317a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10699c0d0>]}
16:36:24.462955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0aa29662-f08e-41e5-95b4-14666fbe317a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686b730>]}
16:36:24.463418 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:36:24.466263 [info ] [MainThread]: 
16:36:24.466890 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:36:24.467902 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:36:24.468223 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:36:25.264955 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:36:25.265314 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:36:25.923500 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:36:25.923974 [info ] [MainThread]: 
16:36:25.929304 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:36:25.929730 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:36:25.930327 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:36:25.930871 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:36:25.931324 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:36:25.935409 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:36:25.936429 [debug] [Thread-1  ]: finished collecting timing info
16:36:25.936673 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:36:25.954991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:36:26.639385 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:36:26.641121 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    

WITH QUESTIONS AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.VIEW_COUNT
    ,B.SCORE
    ,B.OWNER_USER_ID
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,DENSE_RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS POP_RNK
    ,DENSE_RANK() OVER(ORDER BY B.SCORE DESC) AS TREND_RNK
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.ID = B.OWNER_USER_ID
  WHERE
    B.ANSWER_COUNT = 0
    AND B.OWNER_USER_ID IS NOT NULL
)
SELECT *
FROM QUESTIONS
  );
  
16:39:43.265586 [debug] [Thread-1  ]: finished collecting timing info
16:39:43.266504 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0aa29662-f08e-41e5-95b4-14666fbe317a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106af8be0>]}
16:39:43.266888 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 197.34s]
16:39:43.267329 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:39:43.268716 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:39:43.269462 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:39:43.270216 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:39:43.270490 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:39:43.270697 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:39:43.280067 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:39:43.280702 [debug] [Thread-3  ]: finished collecting timing info
16:39:43.280905 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:39:43.305939 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:39:43.306717 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:39:43.309187 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

SELECT *
FROM `salesloft-337304`.`stack_overflow`.`questions`;


16:39:44.524476 [debug] [Thread-3  ]: finished collecting timing info
16:39:44.525100 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0aa29662-f08e-41e5-95b4-14666fbe317a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac2be0>]}
16:39:44.525508 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.26s]
16:39:44.525868 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:39:44.527017 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:39:44.527432 [info ] [MainThread]: 
16:39:44.527744 [info ] [MainThread]: Finished running 1 table model, 1 view model in 200.06s.
16:39:44.528050 [debug] [MainThread]: Connection 'master' was properly closed.
16:39:44.528217 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:39:44.528373 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:39:44.539518 [info ] [MainThread]: 
16:39:44.539881 [info ] [MainThread]: [32mCompleted successfully[0m
16:39:44.540202 [info ] [MainThread]: 
16:39:44.540466 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:39:44.540815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106935fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068815e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686bfa0>]}


============================== 2022-01-05 16:40:13.376390 | a1f77870-d5af-4c01-bcaf-d6cc355f6a7c ==============================
16:40:13.376390 [info ] [MainThread]: Running with dbt=1.0.1
16:40:13.377494 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:40:13.377824 [debug] [MainThread]: Tracking: tracking
16:40:13.399481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133dc160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133dcd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133dc190>]}
16:40:13.489179 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:40:13.490167 [debug] [MainThread]: Partial parsing: update schema file: salesloft_demo://models/example/schema.yml
16:40:13.505300 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:40:13.523472 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:40:13.591033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1f77870-d5af-4c01-bcaf-d6cc355f6a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11354bfa0>]}
16:40:13.598569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1f77870-d5af-4c01-bcaf-d6cc355f6a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133dc400>]}
16:40:13.598982 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:40:13.604764 [info ] [MainThread]: 
16:40:13.605414 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:40:13.606405 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304"
16:40:13.606664 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:40:14.325209 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:40:14.325623 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:40:15.005138 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:40:15.005692 [info ] [MainThread]: 
16:40:15.010669 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:40:15.011069 [info ] [Thread-1  ]: 1 of 2 START table model stack_overflow.questions............................... [RUN]
16:40:15.011616 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:40:15.011811 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:40:15.012010 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:40:15.015530 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:40:15.017028 [debug] [Thread-1  ]: finished collecting timing info
16:40:15.017649 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:40:15.036243 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:40:15.728376 [debug] [Thread-1  ]: Writing runtime SQL for node "model.salesloft_demo.questions"
16:40:15.731192 [debug] [Thread-1  ]: On model.salesloft_demo.questions: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions"} */


  create or replace table `salesloft-337304`.`stack_overflow`.`questions`
  
  
  OPTIONS()
  as (
    

WITH QUESTIONS AS (
  SELECT
     B.ID
    ,B.TITLE
    ,B.BODY
    ,B.CREATION_DATE
    ,B.TAGS
    ,B.VIEW_COUNT
    ,B.SCORE
    ,B.OWNER_USER_ID
    ,A.DISPLAY_NAME
    ,A.AGE
    ,A.REPUTATION
    ,A.LOCATION
    ,DENSE_RANK() OVER(ORDER BY B.VIEW_COUNT DESC) AS POP_RNK
    ,DENSE_RANK() OVER(ORDER BY B.SCORE DESC) AS TREND_RNK
  FROM `bigquery-public-data`.`stackoverflow`.`users` AS A
  LEFT JOIN `bigquery-public-data`.`stackoverflow`.`posts_questions` AS B
    ON A.ID = B.OWNER_USER_ID
  WHERE
    B.ANSWER_COUNT = 0
    AND B.OWNER_USER_ID IS NOT NULL
)
SELECT *
FROM QUESTIONS
  );
  
16:42:23.047406 [debug] [Thread-1  ]: finished collecting timing info
16:42:23.048591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1f77870-d5af-4c01-bcaf-d6cc355f6a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11369baf0>]}
16:42:23.049105 [info ] [Thread-1  ]: 1 of 2 OK created table model stack_overflow.questions.......................... [[32mCREATE TABLE (3.1m rows, 34.3 GB processed)[0m in 128.04s]
16:42:23.049534 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:42:23.050200 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:42:23.050562 [info ] [Thread-3  ]: 2 of 2 START view model stack_overflow.questions_vw............................. [RUN]
16:42:23.051092 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:42:23.051285 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:42:23.051481 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:42:23.060765 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:42:23.061860 [debug] [Thread-3  ]: finished collecting timing info
16:42:23.062167 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:42:23.085006 [debug] [Thread-3  ]: Writing runtime SQL for node "model.salesloft_demo.questions_vw"
16:42:23.086075 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:42:23.088385 [debug] [Thread-3  ]: On model.salesloft_demo.questions_vw: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "model.salesloft_demo.questions_vw"} */


  create or replace view `salesloft-337304`.`stack_overflow`.`questions_vw`
  OPTIONS()
  as -- Use the `ref` function to select from other models

SELECT *
FROM `salesloft-337304`.`stack_overflow`.`questions`;


16:42:24.356725 [debug] [Thread-3  ]: finished collecting timing info
16:42:24.357346 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1f77870-d5af-4c01-bcaf-d6cc355f6a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113669310>]}
16:42:24.357730 [info ] [Thread-3  ]: 2 of 2 OK created view model stack_overflow.questions_vw........................ [[32mOK[0m in 1.31s]
16:42:24.358088 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:42:24.359293 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:42:24.359693 [info ] [MainThread]: 
16:42:24.360000 [info ] [MainThread]: Finished running 1 table model, 1 view model in 130.75s.
16:42:24.360289 [debug] [MainThread]: Connection 'master' was properly closed.
16:42:24.360456 [debug] [MainThread]: Connection 'model.salesloft_demo.questions' was properly closed.
16:42:24.360617 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:42:24.367669 [info ] [MainThread]: 
16:42:24.368080 [info ] [MainThread]: [32mCompleted successfully[0m
16:42:24.368425 [info ] [MainThread]: 
16:42:24.368855 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
16:42:24.369289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113592f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134f4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136b74f0>]}


============================== 2022-01-05 16:44:04.429405 | c544275f-0c85-4f0b-8dcc-f6b0015ec975 ==============================
16:44:04.429405 [info ] [MainThread]: Running with dbt=1.0.1
16:44:04.431035 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile='salesloft_demo', target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
16:44:04.431390 [debug] [MainThread]: Tracking: tracking
16:44:04.458398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111731f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111732370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111732d30>]}
16:44:04.490565 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
16:44:04.491016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c544275f-0c85-4f0b-8dcc-f6b0015ec975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117328e0>]}
16:44:04.539938 [debug] [MainThread]: Parsing macros/etc.sql
16:44:04.543271 [debug] [MainThread]: Parsing macros/catalog.sql
16:44:04.551372 [debug] [MainThread]: Parsing macros/adapters.sql
16:44:04.579443 [debug] [MainThread]: Parsing macros/materializations/seed.sql
16:44:04.582871 [debug] [MainThread]: Parsing macros/materializations/view.sql
16:44:04.586598 [debug] [MainThread]: Parsing macros/materializations/table.sql
16:44:04.591757 [debug] [MainThread]: Parsing macros/materializations/copy.sql
16:44:04.595212 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
16:44:04.613031 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
16:44:04.614832 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
16:44:04.618543 [debug] [MainThread]: Parsing macros/materializations/configs.sql
16:44:04.620772 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
16:44:04.622473 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
16:44:04.639372 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
16:44:04.651425 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
16:44:04.662901 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
16:44:04.667173 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
16:44:04.668997 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
16:44:04.670745 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
16:44:04.674986 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
16:44:04.685793 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
16:44:04.687335 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
16:44:04.696965 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
16:44:04.711792 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
16:44:04.718725 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
16:44:04.721412 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
16:44:04.728104 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
16:44:04.729325 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
16:44:04.731821 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
16:44:04.734035 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
16:44:04.739749 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
16:44:04.755138 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
16:44:04.756494 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
16:44:04.758725 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
16:44:04.760154 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
16:44:04.760952 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
16:44:04.761458 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
16:44:04.762093 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
16:44:04.763342 [debug] [MainThread]: Parsing macros/etc/statement.sql
16:44:04.767416 [debug] [MainThread]: Parsing macros/etc/datetime.sql
16:44:04.775648 [debug] [MainThread]: Parsing macros/adapters/schema.sql
16:44:04.777704 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
16:44:04.780421 [debug] [MainThread]: Parsing macros/adapters/relation.sql
16:44:04.790046 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
16:44:04.793773 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
16:44:04.797853 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
16:44:04.805693 [debug] [MainThread]: Parsing macros/adapters/columns.sql
16:44:04.815252 [debug] [MainThread]: Parsing tests/generic/builtin.sql
16:44:05.026303 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:44:05.036768 [debug] [MainThread]: 1699: static parser successfully parsed example/questions.sql
16:44:05.132585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c544275f-0c85-4f0b-8dcc-f6b0015ec975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118846d0>]}
16:44:05.140019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c544275f-0c85-4f0b-8dcc-f6b0015ec975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111884d60>]}
16:44:05.140554 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:44:05.142870 [info ] [MainThread]: 
16:44:05.143467 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:44:05.144523 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:44:05.144797 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:44:05.863514 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:44:05.864333 [info ] [MainThread]: 
16:44:05.879826 [debug] [Thread-1  ]: Began running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:05.880265 [debug] [Thread-2  ]: Began running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:05.880880 [debug] [Thread-3  ]: Began running node test.salesloft_demo.questions_test
16:44:05.881390 [debug] [Thread-4  ]: Began running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:05.881856 [info ] [Thread-1  ]: 1 of 5 START test not_null_questions_id......................................... [RUN]
16:44:05.882238 [info ] [Thread-2  ]: 2 of 5 START test not_null_questions_vw_id...................................... [RUN]
16:44:05.882812 [info ] [Thread-3  ]: 3 of 5 START test questions_test................................................ [RUN]
16:44:05.883129 [info ] [Thread-4  ]: 4 of 5 START test unique_questions_id........................................... [RUN]
16:44:05.883889 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:44:05.884503 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:44:05.885282 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.salesloft_demo.questions_test"
16:44:05.886131 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:44:05.886478 [debug] [Thread-1  ]: Began compiling node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:05.886733 [debug] [Thread-2  ]: Began compiling node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:05.886999 [debug] [Thread-3  ]: Began compiling node test.salesloft_demo.questions_test
16:44:05.887426 [debug] [Thread-4  ]: Began compiling node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:05.887773 [debug] [Thread-1  ]: Compiling test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:05.888131 [debug] [Thread-2  ]: Compiling test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:05.888565 [debug] [Thread-3  ]: Compiling test.salesloft_demo.questions_test
16:44:05.888883 [debug] [Thread-4  ]: Compiling test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:05.917477 [debug] [Thread-3  ]: Writing injected SQL for node "test.salesloft_demo.questions_test"
16:44:05.918616 [debug] [Thread-2  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:44:05.927816 [debug] [Thread-1  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:44:05.938220 [debug] [Thread-4  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:44:05.939930 [debug] [Thread-3  ]: finished collecting timing info
16:44:05.940895 [debug] [Thread-2  ]: finished collecting timing info
16:44:05.941245 [debug] [Thread-3  ]: Began executing node test.salesloft_demo.questions_test
16:44:05.942023 [debug] [Thread-2  ]: Began executing node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:05.942265 [debug] [Thread-1  ]: finished collecting timing info
16:44:05.948343 [debug] [Thread-4  ]: finished collecting timing info
16:44:05.990247 [debug] [Thread-3  ]: Writing runtime SQL for node "test.salesloft_demo.questions_test"
16:44:05.991660 [debug] [Thread-2  ]: Writing runtime SQL for node "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:44:05.991885 [debug] [Thread-1  ]: Began executing node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:05.992155 [debug] [Thread-4  ]: Began executing node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:05.994774 [debug] [Thread-1  ]: Writing runtime SQL for node "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:44:05.996856 [debug] [Thread-4  ]: Writing runtime SQL for node "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:44:05.997065 [debug] [Thread-3  ]: Opening a new connection, currently in state init
16:44:05.997261 [debug] [Thread-2  ]: Opening a new connection, currently in state init
16:44:05.997843 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:44:05.999301 [debug] [Thread-4  ]: Opening a new connection, currently in state init
16:44:05.999585 [debug] [Thread-3  ]: On test.salesloft_demo.questions_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "test.salesloft_demo.questions_test"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      -- identifying instances where there is no rank

SELECT ID
FROM `salesloft-337304`.`stack_overflow`.`questions`
WHERE
  POP_RNK IS NULL
  OR TREND_RNK IS NULL
GROUP BY 1
      
    ) dbt_internal_test
16:44:06.000693 [debug] [Thread-2  ]: On test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from `salesloft-337304`.`stack_overflow`.`questions_vw`
where id is null



      
    ) dbt_internal_test
16:44:06.002224 [debug] [Thread-1  ]: On test.salesloft_demo.not_null_questions_id.b2d2fa7aea: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from `salesloft-337304`.`stack_overflow`.`questions`
where id is null



      
    ) dbt_internal_test
16:44:06.003702 [debug] [Thread-4  ]: On test.salesloft_demo.unique_questions_id.4c240c9c7e: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "test.salesloft_demo.unique_questions_id.4c240c9c7e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (
  
  select id as unique_field
  from `salesloft-337304`.`stack_overflow`.`questions`
  where id is not null
  
)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
16:44:07.860404 [debug] [Thread-1  ]: finished collecting timing info
16:44:07.860904 [info ] [Thread-1  ]: 1 of 5 PASS not_null_questions_id............................................... [[32mPASS[0m in 1.98s]
16:44:07.861263 [debug] [Thread-1  ]: Finished running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:07.861484 [debug] [Thread-1  ]: Began running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:07.861754 [info ] [Thread-1  ]: 5 of 5 START test unique_questions_vw_id........................................ [RUN]
16:44:07.862192 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:44:07.862376 [debug] [Thread-1  ]: Began compiling node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:07.862553 [debug] [Thread-1  ]: Compiling test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:07.866473 [debug] [Thread-1  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:44:07.867016 [debug] [Thread-1  ]: finished collecting timing info
16:44:07.867216 [debug] [Thread-1  ]: Began executing node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:07.869449 [debug] [Thread-1  ]: Writing runtime SQL for node "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:44:07.871478 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:44:07.873391 [debug] [Thread-1  ]: On test.salesloft_demo.unique_questions_vw_id.9790c3009a: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "node_id": "test.salesloft_demo.unique_questions_vw_id.9790c3009a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (
  
  select id as unique_field
  from `salesloft-337304`.`stack_overflow`.`questions_vw`
  where id is not null
  
)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
16:44:07.958891 [debug] [Thread-2  ]: finished collecting timing info
16:44:07.959454 [info ] [Thread-2  ]: 2 of 5 PASS not_null_questions_vw_id............................................ [[32mPASS[0m in 2.08s]
16:44:07.959804 [debug] [Thread-2  ]: Finished running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:08.075205 [debug] [Thread-3  ]: finished collecting timing info
16:44:08.075690 [info ] [Thread-3  ]: 3 of 5 PASS questions_test...................................................... [[32mPASS[0m in 2.19s]
16:44:08.076043 [debug] [Thread-3  ]: Finished running node test.salesloft_demo.questions_test
16:44:10.658904 [debug] [Thread-4  ]: finished collecting timing info
16:44:10.659418 [info ] [Thread-4  ]: 4 of 5 PASS unique_questions_id................................................. [[32mPASS[0m in 4.77s]
16:44:10.659784 [debug] [Thread-4  ]: Finished running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:12.769880 [debug] [Thread-1  ]: finished collecting timing info
16:44:12.770808 [info ] [Thread-1  ]: 5 of 5 PASS unique_questions_vw_id.............................................. [[32mPASS[0m in 4.91s]
16:44:12.771412 [debug] [Thread-1  ]: Finished running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:12.774479 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:44:12.775026 [info ] [MainThread]: 
16:44:12.775345 [info ] [MainThread]: Finished running 5 tests in 7.63s.
16:44:12.775629 [debug] [MainThread]: Connection 'master' was properly closed.
16:44:12.775803 [debug] [MainThread]: Connection 'test.salesloft_demo.unique_questions_vw_id.9790c3009a' was properly closed.
16:44:12.775959 [debug] [MainThread]: Connection 'test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c' was properly closed.
16:44:12.776123 [debug] [MainThread]: Connection 'test.salesloft_demo.questions_test' was properly closed.
16:44:12.776288 [debug] [MainThread]: Connection 'test.salesloft_demo.unique_questions_id.4c240c9c7e' was properly closed.
16:44:12.808661 [info ] [MainThread]: 
16:44:12.809071 [info ] [MainThread]: [32mCompleted successfully[0m
16:44:12.809397 [info ] [MainThread]: 
16:44:12.809663 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
16:44:12.810029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111898340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118d85e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111abcdf0>]}


============================== 2022-01-05 16:44:52.193812 | ec492b9c-02b5-493e-8c23-a38702c42c18 ==============================
16:44:52.193812 [info ] [MainThread]: Running with dbt=1.0.1
16:44:52.194753 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile='salesloft_demo', target=None, vars='{}', log_cache_events=False, compile=True, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.generate.GenerateTask'>, which='generate', rpc_method='docs.generate')
16:44:52.195026 [debug] [MainThread]: Tracking: tracking
16:44:52.212309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdedf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cde8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cde8e0>]}
16:44:52.270666 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:44:52.271247 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:44:52.279228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec492b9c-02b5-493e-8c23-a38702c42c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e4a0d0>]}
16:44:52.288741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec492b9c-02b5-493e-8c23-a38702c42c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d9a4c0>]}
16:44:52.289249 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:44:52.291176 [info ] [MainThread]: 
16:44:52.291719 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:44:52.292585 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:44:52.292827 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:44:52.959183 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:44:52.959656 [info ] [MainThread]: 
16:44:52.963367 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:44:52.963831 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:44:52.964035 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:44:52.964247 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:44:52.968048 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:44:52.970134 [debug] [Thread-1  ]: finished collecting timing info
16:44:52.970575 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:44:52.971063 [debug] [Thread-1  ]: finished collecting timing info
16:44:52.971675 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:44:52.972547 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:44:52.972819 [debug] [Thread-4  ]: Began running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:52.973169 [debug] [Thread-2  ]: Began running node test.salesloft_demo.questions_test
16:44:52.973582 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:44:52.973734 [debug] [Thread-1  ]: Began running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:52.974164 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:44:52.974541 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.salesloft_demo.questions_test"
16:44:52.974747 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:44:52.975090 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:44:52.975302 [debug] [Thread-4  ]: Began compiling node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:52.975543 [debug] [Thread-2  ]: Began compiling node test.salesloft_demo.questions_test
16:44:52.975757 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:44:52.975938 [debug] [Thread-1  ]: Began compiling node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:52.976134 [debug] [Thread-4  ]: Compiling test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:52.976324 [debug] [Thread-2  ]: Compiling test.salesloft_demo.questions_test
16:44:52.978918 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:44:52.979154 [debug] [Thread-1  ]: Compiling test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:52.993441 [debug] [Thread-4  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:44:52.995831 [debug] [Thread-2  ]: Writing injected SQL for node "test.salesloft_demo.questions_test"
16:44:53.002879 [debug] [Thread-1  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:44:53.003962 [debug] [Thread-4  ]: finished collecting timing info
16:44:53.004214 [debug] [Thread-3  ]: finished collecting timing info
16:44:53.005333 [debug] [Thread-1  ]: finished collecting timing info
16:44:53.005528 [debug] [Thread-4  ]: Began executing node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:53.005658 [debug] [Thread-2  ]: finished collecting timing info
16:44:53.005918 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:44:53.006551 [debug] [Thread-1  ]: Began executing node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:53.006912 [debug] [Thread-4  ]: finished collecting timing info
16:44:53.007316 [debug] [Thread-2  ]: Began executing node test.salesloft_demo.questions_test
16:44:53.007624 [debug] [Thread-3  ]: finished collecting timing info
16:44:53.007866 [debug] [Thread-1  ]: finished collecting timing info
16:44:53.008321 [debug] [Thread-4  ]: Finished running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:44:53.008598 [debug] [Thread-2  ]: finished collecting timing info
16:44:53.008977 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:44:53.009342 [debug] [Thread-1  ]: Finished running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:44:53.009875 [debug] [Thread-2  ]: Finished running node test.salesloft_demo.questions_test
16:44:53.010409 [debug] [Thread-4  ]: Began running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:53.010576 [debug] [Thread-1  ]: Began running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:53.011146 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:44:53.011497 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:44:53.011698 [debug] [Thread-4  ]: Began compiling node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:53.011880 [debug] [Thread-1  ]: Began compiling node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:53.012101 [debug] [Thread-4  ]: Compiling test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:53.012307 [debug] [Thread-1  ]: Compiling test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:53.017832 [debug] [Thread-4  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:44:53.027009 [debug] [Thread-1  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:44:53.028740 [debug] [Thread-4  ]: finished collecting timing info
16:44:53.029006 [debug] [Thread-1  ]: finished collecting timing info
16:44:53.029567 [debug] [Thread-1  ]: Began executing node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:53.029292 [debug] [Thread-4  ]: Began executing node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:53.029781 [debug] [Thread-1  ]: finished collecting timing info
16:44:53.030031 [debug] [Thread-4  ]: finished collecting timing info
16:44:53.030742 [debug] [Thread-1  ]: Finished running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:44:53.031145 [debug] [Thread-4  ]: Finished running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:44:53.032296 [debug] [MainThread]: Connection 'master' was properly closed.
16:44:53.032498 [debug] [MainThread]: Connection 'test.salesloft_demo.unique_questions_vw_id.9790c3009a' was properly closed.
16:44:53.032666 [debug] [MainThread]: Connection 'model.salesloft_demo.questions_vw' was properly closed.
16:44:53.032825 [debug] [MainThread]: Connection 'test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c' was properly closed.
16:44:53.032980 [debug] [MainThread]: Connection 'test.salesloft_demo.questions_test' was properly closed.
16:44:53.039510 [info ] [MainThread]: Done.
16:44:53.042686 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
16:44:53.042925 [info ] [MainThread]: Building catalog
16:44:53.043675 [debug] [MainThread]: Opening a new connection, currently in state init
16:44:54.385261 [debug] [ThreadPool]: Acquiring new bigquery connection "salesloft-337304.information_schema"
16:44:54.386002 [debug] [ThreadPool]: Acquiring new bigquery connection "bigquery-public-data.information_schema"
16:44:54.403515 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:44:54.406438 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:44:54.408197 [debug] [ThreadPool]: On salesloft-337304.information_schema: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "connection_name": "salesloft-337304.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `salesloft-337304`.`stack_overflow`.__TABLES__
        where (upper(dataset_id) = upper('stack_overflow'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `salesloft-337304`.`stack_overflow`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `salesloft-337304`.`stack_overflow`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
16:44:54.445643 [debug] [ThreadPool]: On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`stackoverflow`.__TABLES__
        where (upper(dataset_id) = upper('stackoverflow'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`stackoverflow`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bigquery-public-data`.`stackoverflow`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
16:44:58.120707 [info ] [MainThread]: Catalog written to /Users/bowt/Documents/github/salesloft_demo/target/catalog.json
16:44:58.121594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce2460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f869a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f867f0>]}
16:44:58.541611 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
16:44:58.541931 [debug] [MainThread]: Connection 'salesloft-337304.information_schema' was properly closed.
16:44:58.542106 [debug] [MainThread]: Connection 'bigquery-public-data.information_schema' was properly closed.


============================== 2022-01-05 16:56:25.720269 | 29688ef0-3981-4629-874c-5221d71db199 ==============================
16:56:25.720269 [info ] [MainThread]: Running with dbt=1.0.1
16:56:25.722075 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/bowt/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile='salesloft_demo', target=None, vars='{}', log_cache_events=False, compile=True, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.generate.GenerateTask'>, which='generate', rpc_method='docs.generate')
16:56:25.723052 [debug] [MainThread]: Tracking: tracking
16:56:25.747078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d967f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9678b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9672e0>]}
16:56:25.822356 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:56:25.822972 [debug] [MainThread]: Partial parsing: updated file: salesloft_demo://models/example/questions_vw.sql
16:56:25.840650 [debug] [MainThread]: 1699: static parser successfully parsed example/questions_vw.sql
16:56:25.901008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29688ef0-3981-4629-874c-5221d71db199', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db31f10>]}
16:56:25.910146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29688ef0-3981-4629-874c-5221d71db199', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daeedf0>]}
16:56:25.910571 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 188 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:56:25.912358 [info ] [MainThread]: 
16:56:25.912894 [debug] [MainThread]: Acquiring new bigquery connection "master"
16:56:25.913761 [debug] [ThreadPool]: Acquiring new bigquery connection "list_salesloft-337304_stack_overflow"
16:56:25.914076 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:56:26.784123 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
16:56:26.784830 [info ] [MainThread]: 
16:56:26.791429 [debug] [Thread-1  ]: Began running node model.salesloft_demo.questions
16:56:26.792070 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.salesloft_demo.questions"
16:56:26.792331 [debug] [Thread-1  ]: Began compiling node model.salesloft_demo.questions
16:56:26.792599 [debug] [Thread-1  ]: Compiling model.salesloft_demo.questions
16:56:26.796568 [debug] [Thread-1  ]: Writing injected SQL for node "model.salesloft_demo.questions"
16:56:26.799872 [debug] [Thread-1  ]: finished collecting timing info
16:56:26.800330 [debug] [Thread-1  ]: Began executing node model.salesloft_demo.questions
16:56:26.800667 [debug] [Thread-1  ]: finished collecting timing info
16:56:26.801367 [debug] [Thread-1  ]: Finished running node model.salesloft_demo.questions
16:56:26.802165 [debug] [Thread-3  ]: Began running node model.salesloft_demo.questions_vw
16:56:26.802522 [debug] [Thread-4  ]: Began running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:56:26.803134 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.salesloft_demo.questions_vw"
16:56:26.804073 [debug] [Thread-2  ]: Began running node test.salesloft_demo.questions_test
16:56:26.804352 [debug] [Thread-1  ]: Began running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:56:26.804825 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:56:26.805042 [debug] [Thread-3  ]: Began compiling node model.salesloft_demo.questions_vw
16:56:26.805419 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.salesloft_demo.questions_test"
16:56:26.805786 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:56:26.806015 [debug] [Thread-4  ]: Began compiling node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:56:26.806229 [debug] [Thread-3  ]: Compiling model.salesloft_demo.questions_vw
16:56:26.806411 [debug] [Thread-2  ]: Began compiling node test.salesloft_demo.questions_test
16:56:26.806588 [debug] [Thread-1  ]: Began compiling node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:56:26.806807 [debug] [Thread-4  ]: Compiling test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:56:26.809446 [debug] [Thread-3  ]: Writing injected SQL for node "model.salesloft_demo.questions_vw"
16:56:26.809688 [debug] [Thread-2  ]: Compiling test.salesloft_demo.questions_test
16:56:26.809923 [debug] [Thread-1  ]: Compiling test.salesloft_demo.unique_questions_id.4c240c9c7e
16:56:26.825723 [debug] [Thread-4  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_id.b2d2fa7aea"
16:56:26.829227 [debug] [Thread-2  ]: Writing injected SQL for node "test.salesloft_demo.questions_test"
16:56:26.834869 [debug] [Thread-3  ]: finished collecting timing info
16:56:26.840824 [debug] [Thread-1  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_id.4c240c9c7e"
16:56:26.841623 [debug] [Thread-3  ]: Began executing node model.salesloft_demo.questions_vw
16:56:26.841885 [debug] [Thread-4  ]: finished collecting timing info
16:56:26.842078 [debug] [Thread-2  ]: finished collecting timing info
16:56:26.842501 [debug] [Thread-3  ]: finished collecting timing info
16:56:26.842821 [debug] [Thread-4  ]: Began executing node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:56:26.843047 [debug] [Thread-1  ]: finished collecting timing info
16:56:26.843323 [debug] [Thread-2  ]: Began executing node test.salesloft_demo.questions_test
16:56:26.843803 [debug] [Thread-3  ]: Finished running node model.salesloft_demo.questions_vw
16:56:26.844068 [debug] [Thread-4  ]: finished collecting timing info
16:56:26.844271 [debug] [Thread-1  ]: Began executing node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:56:26.844477 [debug] [Thread-2  ]: finished collecting timing info
16:56:26.845073 [debug] [Thread-3  ]: Began running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:56:26.845454 [debug] [Thread-4  ]: Finished running node test.salesloft_demo.not_null_questions_id.b2d2fa7aea
16:56:26.845680 [debug] [Thread-1  ]: finished collecting timing info
16:56:26.846094 [debug] [Thread-2  ]: Finished running node test.salesloft_demo.questions_test
16:56:26.846453 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:56:26.846723 [debug] [Thread-4  ]: Began running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:56:26.847254 [debug] [Thread-1  ]: Finished running node test.salesloft_demo.unique_questions_id.4c240c9c7e
16:56:26.847685 [debug] [Thread-3  ]: Began compiling node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:56:26.848181 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:56:26.849039 [debug] [Thread-4  ]: Began compiling node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:56:26.848622 [debug] [Thread-3  ]: Compiling test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:56:26.849320 [debug] [Thread-4  ]: Compiling test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:56:26.854591 [debug] [Thread-3  ]: Writing injected SQL for node "test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c"
16:56:26.858576 [debug] [Thread-4  ]: Writing injected SQL for node "test.salesloft_demo.unique_questions_vw_id.9790c3009a"
16:56:26.859185 [debug] [Thread-3  ]: finished collecting timing info
16:56:26.859431 [debug] [Thread-3  ]: Began executing node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:56:26.859575 [debug] [Thread-4  ]: finished collecting timing info
16:56:26.859777 [debug] [Thread-3  ]: finished collecting timing info
16:56:26.859964 [debug] [Thread-4  ]: Began executing node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:56:26.860374 [debug] [Thread-3  ]: Finished running node test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c
16:56:26.860611 [debug] [Thread-4  ]: finished collecting timing info
16:56:26.861222 [debug] [Thread-4  ]: Finished running node test.salesloft_demo.unique_questions_vw_id.9790c3009a
16:56:26.862270 [debug] [MainThread]: Connection 'master' was properly closed.
16:56:26.862465 [debug] [MainThread]: Connection 'test.salesloft_demo.unique_questions_id.4c240c9c7e' was properly closed.
16:56:26.862628 [debug] [MainThread]: Connection 'test.salesloft_demo.not_null_questions_vw_id.6b14f02d1c' was properly closed.
16:56:26.862780 [debug] [MainThread]: Connection 'test.salesloft_demo.unique_questions_vw_id.9790c3009a' was properly closed.
16:56:26.862928 [debug] [MainThread]: Connection 'test.salesloft_demo.questions_test' was properly closed.
16:56:26.875049 [info ] [MainThread]: Done.
16:56:26.878485 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
16:56:26.878741 [info ] [MainThread]: Building catalog
16:56:26.879492 [debug] [MainThread]: Opening a new connection, currently in state init
16:56:28.778893 [debug] [ThreadPool]: Acquiring new bigquery connection "salesloft-337304.information_schema"
16:56:28.779498 [debug] [ThreadPool]: Acquiring new bigquery connection "bigquery-public-data.information_schema"
16:56:28.797036 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:56:28.798842 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:56:28.800862 [debug] [ThreadPool]: On salesloft-337304.information_schema: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "connection_name": "salesloft-337304.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `salesloft-337304`.`stack_overflow`.__TABLES__
        where (upper(dataset_id) = upper('stack_overflow'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `salesloft-337304`.`stack_overflow`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `salesloft-337304`.`stack_overflow`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
16:56:28.839198 [debug] [ThreadPool]: On bigquery-public-data.information_schema: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "salesloft_demo", "target_name": "dev", "connection_name": "bigquery-public-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bigquery-public-data`.`stackoverflow`.__TABLES__
        where (upper(dataset_id) = upper('stackoverflow'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bigquery-public-data`.`stackoverflow`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bigquery-public-data`.`stackoverflow`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
16:56:32.789888 [info ] [MainThread]: Catalog written to /Users/bowt/Documents/github/salesloft_demo/target/catalog.json
16:56:32.790639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9503a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dab1940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd17b80>]}
16:56:33.343722 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
16:56:33.343993 [debug] [MainThread]: Connection 'salesloft-337304.information_schema' was properly closed.
16:56:33.344164 [debug] [MainThread]: Connection 'bigquery-public-data.information_schema' was properly closed.
